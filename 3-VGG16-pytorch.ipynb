{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16\n",
    "\n",
    "In the previous two tutorials we have learned the basics of using two of TensorFlow's high-level APIs, <code>tf.keras</code> and <code>tf.estimator</code>, to build, train and test neural networks. In this tutorial we are going to learn another major deep learning library PyTorch. The neural network that we are going to build is another convolutional neural network, VGG16. VGG stands for visual geometry group, and was created in 2014 and won the first place in the ImageNet object detection challenge and second place in the image classification challenge that year. \n",
    "\n",
    "The key feature of VGG is that it uses small 3 by 3 convolutional kernels instead of larger kernels throughout the architecture, but has more layers stacked upon each other. The success of VGG shows for the first time that deeper networks can increase model performance. The architecture is shown as follows:\n",
    "\n",
    "<img src=\"./files/VGG16.png\">\n",
    "\n",
    "Now let's write our first PyTorch model. PyTorch is a library not only for deep learning, but also for efficient tensor computations with GPUs in general. Most functionalities concerning neural networks are located in <code>torch.nn</code>. For example, <code>torch.nn.Module</code> provides a base class for neural network models. Therefore, we're going to write our VGG16 model as a subclass of this class. To build a neural network architecture, there are two main things that we need to implement. The first one is the constructor of our model subclass. Here we will call the constructor of the base class first, and then define all the layers. And the second one is a forward pass method, which defines how input data will be processed through all the layers in a forward pass.\n",
    "\n",
    "Layers are usually located in <code>torch.nn</code>, and activation functions are actually available at <code>torch.nn.functional</code>. Let's look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call base class instructor\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        # Conv1: 3×3 kernel, 1×1 stride, 64 channels, SAME padding.\n",
    "        # Note that in PyTorch we need to specify the number of padding to be added on each side.\n",
    "        # Here, to keep the shape of the input we need to add 1 padding on each side. For padding,\n",
    "        # stride and kernel_size, if we enter an integer it will be applied to both the width and\n",
    "        # the height dimensions.\n",
    "        # Also note that there is no argument for activation function. We will use the activation\n",
    "        # functions when we write the method for forward pass. Here we are just setting up the\n",
    "        # layers for our model class.\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Conv2: 3×3 kernel, 1×1 stride, 64 channels, SAME padding.\n",
    "        self.conv2 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Pool1: 2×2 kernel, 2×2 stride.\n",
    "        # In MaxPool2d, stride defaults to kernel_size if not specified.\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Conv3-4: 3×3 kernel, 1×1 stride, 128 channels, SAME padding.\n",
    "        self.conv3 = nn.Conv2d(3, 128, 3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(3, 128, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Pool2: 2×2 kernel, 2×2 stride.\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Conv5-7: 3×3 kernel, 1×1 stride, 256 channels, SAME padding.\n",
    "        self.conv5 = nn.Conv2d(3, 256, 3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(3, 256, 3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(3, 256, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Pool3: 2×2 kernel, 2×2 stride.\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Conv8-10: 3×3 kernel, 1×1 stride, 512 channels, SAME padding.\n",
    "        self.conv8 = nn.Conv2d(3, 512, 3, stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(3, 512, 3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(3, 512, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Pool4: 2×2 kernel, 2×2 stride.\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Conv8-13: 3×3 kernel, 1×1 stride, 512 channels, SAME padding.\n",
    "        self.conv11 = nn.Conv2d(3, 512, 3, stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(3, 512, 3, stride=1, padding=1)\n",
    "        self.conv13 = nn.Conv2d(3, 512, 3, stride=1, padding=1)\n",
    "        \n",
    "        # Pool5: 2×2 kernel, 2×2 stride.\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # In TensorFlow we can put a flatten layer here. But in PyTorch there is no flatten layer.\n",
    "        # Therefore, we perform the flatten operation when we write the forward pass method.\n",
    "        \n",
    "        # FullyConnected1: 4096 neurons.\n",
    "        # In PyTorch the dense or fully-connected layer is nn.Linear.\n",
    "        self.fc1 = nn.Linear(in_features=7*7*512, out_features=4096)\n",
    "        \n",
    "        # Dropout1: dropout probability of 0.5.\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # FullyConnected2: 4096 neurons\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        \n",
    "        # Dropout2: dropout probability of 0.5.\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # FullyConnected3: We will use the same dog-vs-cat dataset here. So there will only be\n",
    "        # 2 classes here.\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "        \n",
    "    \n",
    "    # Next we write the forward pass function with input data as an argument. Here we specify how\n",
    "    # the data is transformed by the different layers.\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # Activation function is applied here.\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.pool3(x)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = F.relu(self.conv13(x))\n",
    "        x = self.pool5(x) # Now x should have size [batch_size, 7, 7, 512]\n",
    "        \n",
    "        # The counterpart of tf.reshape is the view method for PyTorch tensors.\n",
    "        x = x.view(-1, 7*7*512) # Similar to TensorFlow, -1 means inferred from other dimensions.\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x) # We keep the logits\n",
    "        return x\n",
    "    \n",
    "# Create a VGG16 instance. Trainable variables are instantly initialized.\n",
    "# The cuda() method transfer the object to GPU.\n",
    "model = VGG16().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to TensorFlow, PyTorch provides convenient ways of preprocessing and loading datasets. There are two important classes at work here: <code>torch.utils.data.Dataset</code> and <code>torch.utils.data.DataLoader</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_pytorch",
   "language": "python",
   "name": "py3_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
